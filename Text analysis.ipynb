{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Импортируем `pymorphy2` (эта чудная библиотека умеет много чего, в том числе ставить слова в начальную форму и определять часть речи, но работает медленно). `Counter`, `pandas` и регулярки нам также пригодятся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Открываем текст и делим его на слова с помощью регулярных выражений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=open('The three ages2.txt').read()\n",
    "words=re.split(r'\\W+', words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Создаем словарь, в котором ключами будут слова из текста, а значениями – количество их повторений. В цикле приводим словаа в начальную форму, избавляемся от случайных пустых строк и служебных частей речи "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[]\n",
    "for i in words:\n",
    "    m=pymorphy2.MorphAnalyzer().parse(i)[0]\n",
    "    if (i and m.tag.POS not in ['PREP', 'CONJ', 'PRCL', 'INTJ', 'NPRO']):\n",
    "        vocab.append(m.normal_form)\n",
    "vocab=dict(Counter(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Создаем `DataFrame` из .csv с частотным словарем русского языка, складываем значения для повторяющихся слов (в этом словаре записаны, например, несколько \"а\" как разные части речи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=pd.read_csv('freqrnc2011.csv', sep='\\t', index_col='Lemma')\n",
    "freq=freq.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Создаем отдельный список для имен, названий, кличек и т.д., которых нет в частотном словаре (сюда попадают и слова типа \"россия\", которые в словаре записаны как \"Россия\", а также слова с ё, увы). Для слов из нашего текста, которые в словаре есть, частоту приводим к общей с .csv единице измерения (слов на миллион) и делим на значение из частотного словаря, убирая из топа слова, которые просто чаще всего в русском языке встречаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "for j in vocab:\n",
    "    if j in freq.index:\n",
    "        vocab[j]*=1000000/len(words)\n",
    "        vocab[j]=round(vocab[j]/freq.loc[j, 'Freq(ipm)'], 2)\n",
    "    else:\n",
    "        names.append([j, vocab[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Сортируем наш словарь (покажем первые 30 и первые 20 списка `names`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('клипер', 14880.95)\n",
      "('траверз', 4960.32)\n",
      "('швартовый', 4960.32)\n",
      "('цокот', 3306.88)\n",
      "('аксельбант', 2834.47)\n",
      "('непристойно', 2834.47)\n",
      "('вассал', 2480.16)\n",
      "('тормашки', 2480.16)\n",
      "('настораживаться', 2480.16)\n",
      "('ливрея', 2204.59)\n",
      "('эполет', 2204.59)\n",
      "('вульгарно', 1984.13)\n",
      "('подбочениться', 1984.13)\n",
      "('раут', 1984.13)\n",
      "('кавалькада', 1803.75)\n",
      "('принесение', 1653.44)\n",
      "('отрубать', 1653.44)\n",
      "('стяг', 1526.25)\n",
      "('гарцевать', 1526.25)\n",
      "('каравай', 1417.23)\n",
      "('андреевский', 1417.23)\n",
      "('платан', 1417.23)\n",
      "('мандарин', 1280.08)\n",
      "('искренно', 1240.08)\n",
      "('неусыпный', 1240.08)\n",
      "('обсадить', 1240.08)\n",
      "('резня', 1102.29)\n",
      "('поднебесный', 1044.28)\n",
      "('повиновение', 1044.28)\n",
      "('пуп', 793.65)\n",
      "\n",
      "['китай', 4]\n",
      "['цзунлиямынь', 1]\n",
      "['4', 1]\n",
      "['ятсный', 1]\n",
      "['1964', 1]\n",
      "['250', 1]\n",
      "['251', 1]\n",
      "['богдыхан', 1]\n",
      "['франция', 1]\n",
      "['россия', 3]\n",
      "['пекин', 1]\n",
      "['канонерка', 1]\n",
      "['чайковский', 4]\n",
      "['кульджинский', 1]\n",
      "['уйгур', 1]\n",
      "['дунганин', 1]\n",
      "['семиречье', 1]\n",
      "['цзунлиямыня', 1]\n",
      "['вели', 1]\n",
      "['англия', 1]\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(list(vocab.items()), key=lambda x: x[1], reverse=True)[:30]:\n",
    "    print(i)\n",
    "print()\n",
    "for j in names[:20]:\n",
    "    print(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
